{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jaxopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Rate of Substition\n",
    "\n",
    "\n",
    "### Derivation\n",
    "\n",
    "Let's say that we have an isoquant where $x$ and $y$ correspond to the amount of inputs used to produce $\\alpha$ units of output\n",
    "\n",
    "$$F(x, y) = \\alpha $$\n",
    "\n",
    "The above equation defines an implicit function which we can call explicitly as follows\n",
    "\n",
    "$$x \\longmapsto \\underset{y}{\\text{solve}}\\ F(x,y) = 0$$\n",
    "\n",
    "The technical rate of substitution is defined the derivative of the isoquant which we can compute as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by writing the isoquant in terms of the function $y(x)$\n",
    "\n",
    "$$F(x,y(x)) = 0$$\n",
    "\n",
    "Now, both the left and right hand sides are functions of $x$, so we can differentiate both side\n",
    "with respect to $x$.\n",
    "\n",
    "$$\\partial _xF(x,y(x)) = 0$$\n",
    "\n",
    "From our understanding of calculus, this derivative can be expressed as follows:\n",
    "\n",
    "$$\\partial _0F(x,y) + \\partial _1F(x,y(x))\\frac{d}{dx}y(x) = 0 $$\n",
    "\n",
    "Hopefully, you can interpret these terms: \n",
    "\n",
    "- **Marginal Product of $x$**: $\\partial _0F(x,y)$\n",
    "- **Marginal Product of $y$**: $\\partial _1F(x,y)$\n",
    "- **Technical Rate of Substitution**: $\\frac{d}{dx}y(x)$\n",
    "\n",
    "We see then that we can express the technical rate of substition in terms of the negative of the ratio of the \n",
    "two marginal products: \n",
    "\n",
    "$$\\frac{d}{dx}y(x) = -\\frac{\\partial _0F(x,y)}{ \\partial _1F(x,y(x))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example\n",
    "\n",
    "To make things concrete, let's create a toy example. We'll consider the following production function\n",
    "\n",
    "$$F(x, y) = Ax^{\\alpha}y^{\\beta}$$\n",
    "\n",
    "Check your understanding -- With the following values, what do you get as the output and the technical rate of substitution? $$A=3, \\alpha=0.8, \\beta=1.3, x=10, y=2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 46.61, TRS: -0.12\n"
     ]
    }
   ],
   "source": [
    "def F(x, y, A=3, alpha=0.8, beta=1.3):\n",
    "    return A*x**alpha*y**beta \n",
    "\n",
    "def implicit_grad(F, x, y):\n",
    "    marginal_product_x, marginal_product_y = jax.grad(F, argnums=(0,1))(x, y)\n",
    "    return -marginal_product_x/marginal_product_y\n",
    "\n",
    "print(f\"Output: {F(10., 2.):.2f}, TRS: {implicit_grad(F, 10., 2.):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our work above, we compute the technical rate of substituion given the quantities of each input. This is not the only starting point (information) from which we can compute the TRS though. We can also compute it if we are given one input and the desired output. **Consider**: How might we incorporate our previous work to build this new function? \n",
    "\n",
    "The task is then to use the level of input of one good and the desired output to compute the input level of the other good. \n",
    "\n",
    "$$F, x, \\text{level} \\longmapsto F, x,  y(F, x, \\text{level}) \\longmapsto\\underbrace{ \\text{TRS}(F, x, y)}_{\\text{We have this!}} $$\n",
    "\n",
    "So we just need to be able to evaluate the implicit function which we can do by calling a solver\n",
    "$$y(F, x, \\text{level})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_function(x, F, level):\n",
    "    solver = jaxopt.GradientDescent(fun=lambda y: (F(x,y)-level)**2, maxiter=500)\n",
    "    return solver.run(1.).params \n",
    "\n",
    "def implicit_grad2(F, x, level):\n",
    "    y = implicit_function(x, F, level)  \n",
    "    return implicit_grad(F, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.076923076923077 -3.0769225109304403\n"
     ]
    }
   ],
   "source": [
    "print(implicit_grad(F, 2., 10.), implicit_grad2(F, 2., F(2., 10.)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mecon",
   "language": "python",
   "name": "mecon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
