{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This is EC201 -- a course where we build Microeconomic models","title":"Welcome"},{"location":"chapters/Game%20Theory/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Introduction I think the most important statement in the chapter is \"suppose we consider round 10\". Hopefully, by the end of this, it will be clear why I think so. We're going to learn how to model strategic interactions between agents with limited information. That is we're going to try to model/predict how agents will act when the outcome of interest depends on both their actions and of other agents around them. The term agent is synonymous in this context with the term \"decision-maker\". We'll begin by introducing a relatively general way to model strategic interactions and then illustrate how the toy examples covered in the textbook correspond to a very particular case of the framework. The assumption here is that you have already seen games like Prisoners-delimma and the like from your introduction to microeconomics class. Framework We're going to consider the model of an agent and an environment . An agent, as mentioned above is a decision maker, (i.e. one who makes decisions). The environment cab be thought of as the state of the world together with the mechanism that generates new state of the world. update :: state -> action -> state -> reward For the moment, we're going to focus on environments where the state of the world doesn't matter. Which means we can simpify the above function to: update :: action -> reward Two Modeling Options Which one should we choose? Hopefully the question that you are asking yourself right now is, how do we incorporate the actions of other agents into this framework? There's essentially two ways, we can think of them as \"silently\" comming into the update function, or we can think of them as a component of the state, and that therefore the state is only partially observable. We're going to use the latter framework with the understanding that the each agent has the same observable state, but different true states. Example Nash Equilibirum Under our framework, a Nash equilibrium is a situation where no one would be better off by choosing a different action assuming everyone kept theirs (there is no incentive to deviate) Underactuated How should we think about underactuated in a discrete time system? $$\\text{new_state} = f(\\text{state}, \\text{action})$$ From the perspective of each individual agent, it can consider all of the other agents that it's interacting with to be part of the environment","title":"Adv Game Theory"},{"location":"chapters/Game%20Theory/#introduction","text":"I think the most important statement in the chapter is \"suppose we consider round 10\". Hopefully, by the end of this, it will be clear why I think so. We're going to learn how to model strategic interactions between agents with limited information. That is we're going to try to model/predict how agents will act when the outcome of interest depends on both their actions and of other agents around them. The term agent is synonymous in this context with the term \"decision-maker\". We'll begin by introducing a relatively general way to model strategic interactions and then illustrate how the toy examples covered in the textbook correspond to a very particular case of the framework. The assumption here is that you have already seen games like Prisoners-delimma and the like from your introduction to microeconomics class.","title":"Introduction"},{"location":"chapters/Game%20Theory/#framework","text":"We're going to consider the model of an agent and an environment . An agent, as mentioned above is a decision maker, (i.e. one who makes decisions). The environment cab be thought of as the state of the world together with the mechanism that generates new state of the world. update :: state -> action -> state -> reward For the moment, we're going to focus on environments where the state of the world doesn't matter. Which means we can simpify the above function to: update :: action -> reward","title":"Framework"},{"location":"chapters/Game%20Theory/#two-modeling-options","text":"Which one should we choose? Hopefully the question that you are asking yourself right now is, how do we incorporate the actions of other agents into this framework? There's essentially two ways, we can think of them as \"silently\" comming into the update function, or we can think of them as a component of the state, and that therefore the state is only partially observable. We're going to use the latter framework with the understanding that the each agent has the same observable state, but different true states.","title":"Two Modeling Options"},{"location":"chapters/Game%20Theory/#example","text":"","title":"Example"},{"location":"chapters/Game%20Theory/#nash-equilibirum","text":"Under our framework, a Nash equilibrium is a situation where no one would be better off by choosing a different action assuming everyone kept theirs (there is no incentive to deviate)","title":"Nash Equilibirum"},{"location":"chapters/Game%20Theory/#underactuated","text":"How should we think about underactuated in a discrete time system? $$\\text{new_state} = f(\\text{state}, \\text{action})$$ From the perspective of each individual agent, it can consider all of the other agents that it's interacting with to be part of the environment","title":"Underactuated"},{"location":"chapters/asymmetric%20information/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Represent Information via the conditional expectation function $$ \\big(\\Omega, \\mathcal{F}, \\mathbb{P} \\big) $$ Let $\\Omega$ denote the set of 100 cars Let $A = {\\omega \\in \\Omega | \\omega \\text{ is a lemon} }\\subset \\Omega$ and $A^c = {\\omega \\in \\Omega | \\omega \\text{ is a plum} }\\subset \\Omega$ Let $\\mathbb{P}(A) = p, \\mathbb{P}(A^c) = 1 - p add table here about how the sellers value their car less than the buyers $$$$","title":"Asymmetric Information"},{"location":"chapters/chapter1/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import jax import jax.numpy as jnp import matplotlib.pyplot as plt from functools import partial Motivating Quote Reflection: Constructing a Model Can you construct a model to help you understand an some Economic relationship? We'll yes and no. To start with, in order to build a model you need to have some understanding of the issue/topic of interest so as to determine which aspects of reality don't need to be faithfully captured by the model. But in addition to that, an Economic model without any data is simply the the result of composing several of your own ideas together. So, does it help you understand an Economic reality, or does the act of creating a model help you better understand your own thoughts on the Economic reality? Market Equilibrium: Where Supply Meets Demand Let's say that we're back in the Spring of 2020 and that we're working for Petco, a company that produces dog food. Our manager comes to us and asks us to model how a shutdown for several months might affect the dog food market. We decide to approach this in three steps. First we'll model the demand for dog food, then well model the supply before putting these pieces together to get a rough picture/understanding of the entire market. Demand We know that quantity demanded is a function of price. When price increase, the quantity demanded falls. $$Q_{\\text{demand}} = f(\\text{price})$$ With the pandemic, the relationship remains, but we now want to think about how social distancing and remote work might affect the demand for dog food. To do so, we augment our demand function to include the months of the pandemic as an argument. $$\\begin{aligned} Q_{\\text{dogs}} &= g(\\text{price}, \\textrm{months}) \\\\ Q_{\\text{dog_food}} &= f(\\text{price}, \\textrm{months}) \\\\ f(\\text{price}, \\textrm{months}) &= h(g(\\text{price}, \\textrm{months}) , \\text{price})\\end{aligned}$$ def q_dog ( price_dog_food , months ): return 10 - price_dog_food + months for i in range ( 1 , 12 , 2 ): xs = jnp . linspace ( 1 , 12 , 100 ) ys = partial ( q_dog , months = i )( xs ) plt . plot ( xs , ys , label = i ) plt . title ( 'Price of Dog' , loc = 'left' , size = 14 ) plt . xlabel ( 'Quantity of Dogs' , size = 14 ) plt . legend ( frameon = False , title = 'Months in Pandemic' , ncol = 2 ) plt . show () def q_dog_food ( price_dog_food , months ): num_dogs = q_dog ( price_dog_food , months ) return 120 + 0.5 * num_dogs + months for i in range ( 1 , 12 , 2 ): xs = jnp . linspace ( 1 , 12 , 100 ) ys = partial ( q_dog_food , months = i )( xs ) plt . plot ( xs , ys , label = i ) plt . title ( 'Price of Dog Food' , loc = 'left' , size = 14 ) plt . xlabel ( 'Quantity of Dog Food' , size = 14 ) plt . legend ( frameon = False , title = 'Months in Pandemic' , ncol = 2 ) plt . show () What if ... We can now ask our selves questions such as, what if staying at home not only changes one's willingness to have a dog, but also their willingness to pay for daily expenses of owning a dog. Specifically, what if $g$ changes as a result of the pandemic?","title":"The First Model"},{"location":"chapters/chapter1/#motivating-quote","text":"","title":"Motivating Quote"},{"location":"chapters/chapter1/#reflection-constructing-a-model","text":"Can you construct a model to help you understand an some Economic relationship? We'll yes and no. To start with, in order to build a model you need to have some understanding of the issue/topic of interest so as to determine which aspects of reality don't need to be faithfully captured by the model. But in addition to that, an Economic model without any data is simply the the result of composing several of your own ideas together. So, does it help you understand an Economic reality, or does the act of creating a model help you better understand your own thoughts on the Economic reality?","title":"Reflection: Constructing a Model"},{"location":"chapters/chapter1/#market-equilibrium-where-supply-meets-demand","text":"Let's say that we're back in the Spring of 2020 and that we're working for Petco, a company that produces dog food. Our manager comes to us and asks us to model how a shutdown for several months might affect the dog food market. We decide to approach this in three steps. First we'll model the demand for dog food, then well model the supply before putting these pieces together to get a rough picture/understanding of the entire market.","title":"Market Equilibrium: Where Supply Meets Demand"},{"location":"chapters/chapter1/#demand","text":"We know that quantity demanded is a function of price. When price increase, the quantity demanded falls. $$Q_{\\text{demand}} = f(\\text{price})$$ With the pandemic, the relationship remains, but we now want to think about how social distancing and remote work might affect the demand for dog food. To do so, we augment our demand function to include the months of the pandemic as an argument. $$\\begin{aligned} Q_{\\text{dogs}} &= g(\\text{price}, \\textrm{months}) \\\\ Q_{\\text{dog_food}} &= f(\\text{price}, \\textrm{months}) \\\\ f(\\text{price}, \\textrm{months}) &= h(g(\\text{price}, \\textrm{months}) , \\text{price})\\end{aligned}$$ def q_dog ( price_dog_food , months ): return 10 - price_dog_food + months for i in range ( 1 , 12 , 2 ): xs = jnp . linspace ( 1 , 12 , 100 ) ys = partial ( q_dog , months = i )( xs ) plt . plot ( xs , ys , label = i ) plt . title ( 'Price of Dog' , loc = 'left' , size = 14 ) plt . xlabel ( 'Quantity of Dogs' , size = 14 ) plt . legend ( frameon = False , title = 'Months in Pandemic' , ncol = 2 ) plt . show () def q_dog_food ( price_dog_food , months ): num_dogs = q_dog ( price_dog_food , months ) return 120 + 0.5 * num_dogs + months for i in range ( 1 , 12 , 2 ): xs = jnp . linspace ( 1 , 12 , 100 ) ys = partial ( q_dog_food , months = i )( xs ) plt . plot ( xs , ys , label = i ) plt . title ( 'Price of Dog Food' , loc = 'left' , size = 14 ) plt . xlabel ( 'Quantity of Dog Food' , size = 14 ) plt . legend ( frameon = False , title = 'Months in Pandemic' , ncol = 2 ) plt . show ()","title":"Demand"},{"location":"chapters/chapter1/#what-if","text":"We can now ask our selves questions such as, what if staying at home not only changes one's willingness to have a dog, but also their willingness to pay for daily expenses of owning a dog. Specifically, what if $g$ changes as a result of the pandemic?","title":"What if ..."},{"location":"chapters/chapter2/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import jax import jax.numpy as jnp import matplotlib.pyplot as plt from functools import partial Motivating Quote -- Robert Gallagher ``The big problem in probability theory and particularly stochastic processes is not so much how do you solve well-posed problems. Anybody can do that. Or anybody who has a little bit of background can do it. The hard problem is finding the right models for a real-world problem.'' Introduction Like very few people who I interact with on a daily basis, I find the NBA offseason exilarating. As I am writing this sentence now in early July, Kevin Durant's future is still up in the air. Will he stay in Brooklyn? Will he stay with Kyrie? Could he possibly end up with the team up North? I find the inherent uncertainty of this event exciting. It gives plausibility to the thought of seeing Kevin Durant run pick-in-rolls with Ja Morant, or stretching the court with another long wing in Brandom Ingram. On the flip side, when I read articles regarding the current health of wall street, when I see headlines of an oncomming recession, it is easy to feel moments of anxiety. As we can all atest to, uncertainty can be both exilarating or debilitating depending on the context. Our task as Economist is to drain the emotion. We simply want to incorporate uncertainty into our Economic models to enhance them. Approach When people look at how difficult a topic is to learn, they might start by considering the number of elements in the topic. I might be wrong about this, but I believe this rough heuristic shapes how many people teach classes on statistics and probability. If you can reduce the number of ideas that a student has to consider the easier it should be to learn, i.e. the less overwhelmed they are. I buy the point that it's important to introduce material in a way so as to decrease the likelihood of overwhelming students (that's why we're starting so early in the semester with probability - we're going to introduce it piece by piece), but I would push back on the idea that having fewer elements to learn makes the topic easier to understand. Learning a new topic can be difficult for the following three reasons. (1) It can be hard to understand why you should care about the topic (2) It can be hard to understand which aspects of the topic are important and which are just details and (3) It can be hard to understand how the components of the topic fit together. With this understanding in mind, I believe introducing additional components can be helpful it if enables students to better compose ideas. That is, if the addition details allows students to better understand how ideas relate to each others. I think this is the key to understanding probability theory. Understanding the fundamentals will make it easier/ simpler to see how things relate to each other. If you never understand the fundamentals you'll simply have a collection of ideas in your head, which will be harder to keep track of and harder to work with in practice. Probability Space We'll start by introducing a probility space. We want to capture a lack of information, a lack of knowledge about some aspect of the world. $$\\begin{aligned}\\big( \\Omega, \\mathcal{F}, \\mathbb{P}) \\end{aligned}$$","title":"Introduction to Uncertainty"},{"location":"chapters/chapter2/#motivating-quote-robert-gallagher","text":"``The big problem in probability theory and particularly stochastic processes is not so much how do you solve well-posed problems. Anybody can do that. Or anybody who has a little bit of background can do it. The hard problem is finding the right models for a real-world problem.''","title":"Motivating Quote --Robert Gallagher"},{"location":"chapters/chapter2/#introduction","text":"Like very few people who I interact with on a daily basis, I find the NBA offseason exilarating. As I am writing this sentence now in early July, Kevin Durant's future is still up in the air. Will he stay in Brooklyn? Will he stay with Kyrie? Could he possibly end up with the team up North? I find the inherent uncertainty of this event exciting. It gives plausibility to the thought of seeing Kevin Durant run pick-in-rolls with Ja Morant, or stretching the court with another long wing in Brandom Ingram. On the flip side, when I read articles regarding the current health of wall street, when I see headlines of an oncomming recession, it is easy to feel moments of anxiety. As we can all atest to, uncertainty can be both exilarating or debilitating depending on the context. Our task as Economist is to drain the emotion. We simply want to incorporate uncertainty into our Economic models to enhance them.","title":"Introduction"},{"location":"chapters/chapter2/#approach","text":"When people look at how difficult a topic is to learn, they might start by considering the number of elements in the topic. I might be wrong about this, but I believe this rough heuristic shapes how many people teach classes on statistics and probability. If you can reduce the number of ideas that a student has to consider the easier it should be to learn, i.e. the less overwhelmed they are. I buy the point that it's important to introduce material in a way so as to decrease the likelihood of overwhelming students (that's why we're starting so early in the semester with probability - we're going to introduce it piece by piece), but I would push back on the idea that having fewer elements to learn makes the topic easier to understand. Learning a new topic can be difficult for the following three reasons. (1) It can be hard to understand why you should care about the topic (2) It can be hard to understand which aspects of the topic are important and which are just details and (3) It can be hard to understand how the components of the topic fit together. With this understanding in mind, I believe introducing additional components can be helpful it if enables students to better compose ideas. That is, if the addition details allows students to better understand how ideas relate to each others. I think this is the key to understanding probability theory. Understanding the fundamentals will make it easier/ simpler to see how things relate to each other. If you never understand the fundamentals you'll simply have a collection of ideas in your head, which will be harder to keep track of and harder to work with in practice.","title":"Approach"},{"location":"chapters/chapter2/#probability-space","text":"We'll start by introducing a probility space. We want to capture a lack of information, a lack of knowledge about some aspect of the world. $$\\begin{aligned}\\big( \\Omega, \\mathcal{F}, \\mathbb{P}) \\end{aligned}$$","title":"Probability Space"},{"location":"chapters/demand/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Differentiating Implicit Functions $$ x_1 = x_1(p,m) $$ \"Homothetic preferences are very convienent since the income effects are so simple. Unfortunately, homothetic preferences aren't very realistic for the same reason! But they will often be of use in our examples.\" Normal good: $\\partial _2 x_1 > 0 $ Engel curve: graph of the quantity demanded as a function of income ($m, x_1$ graph)","title":"Demand"},{"location":"chapters/extra/","text":"$ mkdir /User/patrickpower/Library/Jupyter/kernels/mecon","title":"Extra"},{"location":"chapters/firm_supply/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); The supply curve of a firm depends on the market that a firm finds itself in The three ways to view producer surplus Fundamental Theorem of Calculus Work through the example The price-taking firm's problem $$ \\underset{y}{py} - c(y) $$ First order condition: $$p - c'(y) = 0 $$ Second order condition: $$ -c''(y) \\leq 0 $$","title":"Firm Supply"},{"location":"chapters/monopolies/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import jax import jax.numpy as jnp import matplotlib.pyplot as plt from functools import partial large companies design new programming langauges -- see here","title":"Monopolies"},{"location":"chapters/rl/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); This note is based largely on David Silver's course on reinforcement learning The Science of Decision Making We consider the Active learning set-up where \"agents\" make decisions and from these decisions, receive new experiences/observations and rewards. $$\\begin{aligned}\\text{Actions} &: A_t \\\\ \\text{Observations, Reward} &: O_{t+1}, R_{t+1} \\end{aligned}$$ Combining these two ideas, our decisions/actions can depend on the entire experience (History) $$H_t = A_1, O_1, R_1, \\dots, A_t, O_t, R_t$$ Defering for the moment any discussion about how we might define an observation or reward for a given problem, the central challenge is how can we learn from our history? - To do so, we introduce this idea of state which is some function of the history $$S_t = f(H_t)$$ Reward Hypothesis \"Goals can be described by the maximization of expected cummulative reward\" $$\\mathbb{E}\\Big[ \\sum R_{t}\\Big]$$ Defining the reward can be challenging Consider What is the reward? (this can be very high dimensional, how should we make it a scalar?) What is the state? how does the markov process afect the type of reward processes we can learn from?","title":"Sequential Decision Making"},{"location":"chapters/rl/#the-science-of-decision-making","text":"We consider the Active learning set-up where \"agents\" make decisions and from these decisions, receive new experiences/observations and rewards. $$\\begin{aligned}\\text{Actions} &: A_t \\\\ \\text{Observations, Reward} &: O_{t+1}, R_{t+1} \\end{aligned}$$ Combining these two ideas, our decisions/actions can depend on the entire experience (History) $$H_t = A_1, O_1, R_1, \\dots, A_t, O_t, R_t$$ Defering for the moment any discussion about how we might define an observation or reward for a given problem, the central challenge is how can we learn from our history? - To do so, we introduce this idea of state which is some function of the history $$S_t = f(H_t)$$ Reward Hypothesis \"Goals can be described by the maximization of expected cummulative reward\" $$\\mathbb{E}\\Big[ \\sum R_{t}\\Big]$$ Defining the reward can be challenging Consider What is the reward? (this can be very high dimensional, how should we make it a scalar?) What is the state? how does the markov process afect the type of reward processes we can learn from?","title":"The Science of Decision Making"},{"location":"chapters/utility/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Quasilinear utility functions are not particularly realistic, but they are very easy to work with Ordinary differential equations !!! info ODE problems are informally divided into \"stiff\" and \"non-stiff\" problems. \"Stiffness\" generally refers to how difficult an equation is to solve numerically. Non-stiff problems are quite common, and usually solved using straightforward techniques like explicit Runge--Kutta methods. Stiff problems usually require more computationally expensive techniques, like implicit Runge--Kutta methods. $$ \\textrm{Preference Relation} \\rightarrow \\textrm{Utility Function} $$ What aspects of the underlying space does the function preserve? Marginal utility is not we'll defined","title":"Utils"},{"location":"chapters/utility/#ordinary-differential-equations","text":"!!! info ODE problems are informally divided into \"stiff\" and \"non-stiff\" problems. \"Stiffness\" generally refers to how difficult an equation is to solve numerically. Non-stiff problems are quite common, and usually solved using straightforward techniques like explicit Runge--Kutta methods. Stiff problems usually require more computationally expensive techniques, like implicit Runge--Kutta methods. $$ \\textrm{Preference Relation} \\rightarrow \\textrm{Utility Function} $$ What aspects of the underlying space does the function preserve? Marginal utility is not we'll defined","title":"Ordinary differential equations"},{"location":"math/Math%20on%20the%20Computer/","text":"Hopefully, I've highlighted that writing math on the computer is nothing to sweat over. It may not be obvious though why we want to write math on the computer. Why not stick to pen/pencil and paper? There are two reasons. First writing math on the computer allows us to work at different levels of abstraction. Second its easier to play with your model if its written on the computer. You can change one aspect with one key stroke and see how your predictions change. Indeed to the extent possible, the code that we write on the computer will fit within the functional programming discipline so as to minimize the conceptual difference. First a pure function is a unit of code whose return value is entirely determined by its inputs, and has no observable effect other than simply returning a value. -- Stephen Diehl","title":"Math on the Computer"},{"location":"math/convexity/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); The pointwise maximum preserves convexity $$\\text{max}\\ (f_1, f_2)$$","title":"Convexity"},{"location":"math/dependent_functions/","text":"-- ref 1 -- ref 2","title":"Dependent Functions"},{"location":"math/gradient_descent/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import jax jax . config . update ( \"jax_enable_x64\" , True ) No higher order derivatives ### Visualization Resources - [ Ref ]( https : // github . com / lilipads / gradient_descent_viz ) $$\\begin{align} \\underset{x}{\\text{min}} \\ f(x) \\end{align}$$ $$ \\begin{align}\\text{objective function}:& \\quad \\underset{x}{\\text{min}} \\ f(x_0) + \\nabla f(x_0)^T (x-x_0) + \\frac{1}{\\alpha}|x-x_0 | \\\\ \\text{update rule}:& \\quad x_{t-1} = x_t - \\alpha _t \\nabla f(x_t)\\end{align} $$","title":"Gradient Descent"},{"location":"math/newton%20method/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import jax jax . config . update ( \"jax_enable_x64\" , True ) import jax.numpy as jnp import matplotlib.pyplot as plt Optimization starts with approximating a function To help motivate us, let's consider the following function: $$ \\begin{align}\\text{objective function}:& \\quad \\underset{x}{\\text{min}} \\\\ \\text{update rule}:& \\quad x_{t-1} = x_t - \\alpha _t H(x_t)^{-1}\\nabla f(x_t)\\end{align} $$ def f ( x ): return jnp . log ( x ** 2 + 1.0 + jnp . sin ( x * 3 )) + 1.5 xs = jnp . linspace ( - 3. , 3. , 1000 ) ys = f ( xs ) plt . plot ( xs , ys ) plt . show () Let's approximate this function def make_approx2 ( x0 , f ): def f_approx ( x ): return f ( x0 ) + jax . grad ( f )( x0 ) * ( x - x0 ) + ( 1 / 2 ) * jax . grad ( jax . grad ( f ))( x0 ) * ( x - x0 ) ** 2 return f_approx def make_approx1 ( x0 , f ): def f_approx ( x ): return f ( x0 ) + jax . jacobian ( f )( x0 ) * ( x - x0 ) return f_approx x0 = .5 f_approx = make_approx2 ( x0 , f ) xs = jnp . linspace ( - 3. , 3. , 1000 ) ys = f ( xs ) ys_approx = jax . vmap ( f_approx )( xs ) plt . plot ( xs , ys ) plt . plot ( xs , ys_approx ) plt . show () To mimize a scalar valued function, we often want to find (a/the) root of a related vector valued function $$\\begin{align} \\underset{x}{\\text{min}} \\ f(x) \\iff \\text{solve:} \\ \\nabla f(x)= 0\\end{align}$$ To solve a systems of equations (here n x n), we can apply Newton's method which essentially proceeds as follows: at each iteration, we first linearly approximate the function $$\\begin{align} \\nabla f (x) \\approx \\nabla f (x_0) + \\nabla ^2 f(x_0)(x-x_0)\\end{align}$$ and then we find the root of linear approximation to get the next value $$\\begin{align} 0 &= \\nabla f (x_0) + \\nabla ^2 f(x_0)(x-x_0)\\\\ x &= x_0 - \\nabla ^2 f(x_0)^{-1}\\nabla f(x_0)\\end{align}$$ def newton_method ( f , x , iters = 1000 ): def update ( carry , t ): x = carry x_new = x - jnp . dot (( jax . grad ( f )( x )) ** ( - 1 ), f ( x )) return x_new , x_new ans , hist = jax . lax . scan ( update , x , xs = None , length = iters ) return ans , hist def objective ( x ): return jnp . log ( x ** 2 + 1.0 + jnp . sin ( x * 3 )) + 1.5 ans , hist = newton_method ( jax . grad ( objective ), 1. ) print ( ans ) 0.68057626 plt . plot ( hist ) plt . show ()","title":"Newton's Method"},{"location":"other/quotes/","text":"Throughout my life as professional programmer, I\u2019ve realized there are two different groups of programmers. Those that see programming languages primarily as an instrument of human reason and those that see as a means of production for specific tasks.","title":"Quotes"},{"location":"other/dex/effects/","text":"We suppose it is a useful property of the surface language to be able to distinguish between units of logic which have effects, and to be able to classify these type of effects in order to greater reason about program composition.-- Stephen Diehl the compiler is aware of the effect it carries and the following function can be written without an annotation and effect inference will deduce the appropriate signature without the user having to specify it.-- Stephen Diehl","title":"Effects"},{"location":"overview/overview/","text":"Microeconomics Motivation Models are constructed in response to questions. The key word here is constructed, meaning that models are built. When you build something, the first question to ask is whether the thing you built is any good, whether it's useful. The usefulness depends largely on who the model is for. Perhaps you are writing down a model to help organize your thoughts. Then you may not need a complete model. Or, perhaps you are asked to help predict the effects of a some government policy such as Right to Counsel . Then you probably want to decide on who this policy might effect, think through how each party involved might respond, and suggest a range of possible outcomes. The aim of this course is to help you learn to write down models so that you may be in a better position to suggest answers to questions of interest. You can think of this as a English class that you may have taken in high school where instead of writing an essay, we're going to be learning how to write down models. Like an high school essay, the topic of these models will be your choice! Assessments We will have bi-weekly group assignments, two midterms and a final. Teaching Philosophy : Ideas are explained at the level of detail so as to enable composition (it should feel like you're playing with legos ). Based on my experience, I found this is best done by writing math on computer. Some people will consider this to be programming, but those people would be wrong. It's just writing math on a computer. On the first day of class, you will learn everything you need to know about writing math on the computer.","title":"Overview"},{"location":"overview/overview/#microeconomics","text":"","title":"Microeconomics"},{"location":"overview/overview/#motivation","text":"Models are constructed in response to questions. The key word here is constructed, meaning that models are built. When you build something, the first question to ask is whether the thing you built is any good, whether it's useful. The usefulness depends largely on who the model is for. Perhaps you are writing down a model to help organize your thoughts. Then you may not need a complete model. Or, perhaps you are asked to help predict the effects of a some government policy such as Right to Counsel . Then you probably want to decide on who this policy might effect, think through how each party involved might respond, and suggest a range of possible outcomes. The aim of this course is to help you learn to write down models so that you may be in a better position to suggest answers to questions of interest. You can think of this as a English class that you may have taken in high school where instead of writing an essay, we're going to be learning how to write down models. Like an high school essay, the topic of these models will be your choice!","title":"Motivation"},{"location":"overview/overview/#assessments","text":"We will have bi-weekly group assignments, two midterms and a final.","title":"Assessments"},{"location":"overview/overview/#teaching-philosophy","text":"Ideas are explained at the level of detail so as to enable composition (it should feel like you're playing with legos ). Based on my experience, I found this is best done by writing math on computer. Some people will consider this to be programming, but those people would be wrong. It's just writing math on a computer. On the first day of class, you will learn everything you need to know about writing math on the computer.","title":"Teaching Philosophy:"}]}