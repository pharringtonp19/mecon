{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "\n",
    "I think the most important statement in the chapter is \"suppose we consider round 10\". Hopefully, by the end of this, it will be clear why I think so. \n",
    "\n",
    "--- \n",
    "We're going to learn how to model strategic interactions between agents with limited information. That is we're going to try to model/predict how agents will act when the outcome of interest depends on both their actions and of other agents around them. The term agent is synonymous in this context with the term \"decision-maker\".\n",
    "\n",
    "We'll begin by introducing a relatively general way to model strategic interactions and then illustrate how the toy examples covered in the textbook correspond to a very particular case of the framework. The assumption here is that you have already seen games like Prisoners-delimma and the like from your introduction to microeconomics class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Framework**\n",
    "\n",
    "We're going to consider the model of an **agent** and an **environment**. An agent, as mentioned above is a decision maker, (i.e. one who makes decisions). The environment cab be thought of as the state of the world together with the mechanism that generates new state of the world. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```haskell\n",
    "update :: state -> action -> state -> reward\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the moment, we're going to focus on environments where the state of the world doesn't matter. Which means we can simpify the above function to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```haskell\n",
    "update :: action -> reward\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Two Modeling Options**\n",
    "- <span style=\"color:red\">Which one should we choose?</span>\n",
    "Hopefully the question that you are asking yourself right now is, how do we incorporate the actions of other agents into this framework? There's essentially two ways, we can think of them as \"silently\" comming into the`update` function, or we can think of them as a component of the state, and that therefore the state is only partially observable. We're going to use the latter framework with the understanding that the each agent has the same observable state, but different true states. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Nash Equilibirum**\n",
    "\n",
    "Under our framework, a Nash equilibrium is a situation where no one would be better off by choosing a different action assuming everyone kept theirs (there is no incentive to deviate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Underactuated**\n",
    "- <span style=\"color:red\">How should we think about underactuated in a discrete time system?</span>\n",
    "\n",
    "$$\\text{new\\_state} = f(\\text{state}, \\text{action})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
